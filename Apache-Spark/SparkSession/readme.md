# 📚 SparkSession Learning Roadmap

| Week  | Topic                                          | Concepts Covered                                                                 | Example Exercises                                 | Resources                                                                                                                                 |
| ----- | ---------------------------------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| 1️⃣ | **Introduction to Spark & SparkSession** | What is Spark, SparkSession vs SparkContext, Lazy evaluation, Spark architecture | Initialize `SparkSession`, basic read/write CSV | [Spark Docs: Getting Started](https://spark.apache.org/docs/latest/sql-getting-started.html)                                                 |
| 2️⃣ | **Working with DataFrames**              | Reading from CSV/JSON/Parquet, schema inference,`.show()`,`.printSchema()`   | Read a JSON file and print schema                 | [DataFrame API Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html#datasets-and-dataframes)                               |
| 3️⃣ | **Column Operations**                    | Selecting columns, filtering rows, adding new columns (`withColumn`), renaming | Filter rows where age > 30                        | [PySpark Column API](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/column.html)                                      |
| 4️⃣ | **Data Cleaning & Transformation**       | `na.drop()`,`na.fill()`, casting types, string operations                    | Clean missing age values and convert to integer   | [Working with Missing Data](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameNaFunctions.html) |
| 5️⃣ | **Aggregation & GroupBy**                | `groupBy()`,`agg()`, built-in functions like `avg`,`count`,`sum`       | Group people by city and calculate average age    | [Aggregations](https://spark.apache.org/docs/latest/sql-ref-functions-aggregate.html)                                                        |
| 6️⃣ | **Joins in Spark**                       | Inner, left, right, full joins                                                   | Join users and orders data                        | [Joins in PySpark](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.join.html)                |
| 7️⃣ | **Sorting, Ordering & Window Functions** | `orderBy()`,`sort()`,`row_number()`,`rank()`                             | Get top 3 highest salaries by department          | [Window Functions](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-window.html)                                               |
| 8️⃣ | **Saving & Loading Data**                | Writing to CSV, Parquet, JSON, partitioning                                      | Save grouped data to Parquet                      | [I/O Options](https://spark.apache.org/docs/latest/sql-data-sources.html)                                                                    |
| 9️⃣ | **SQL with SparkSession**                | Registering temp views, running SQL queries                                      | Run `SELECT * FROM people WHERE age > 30`       | [Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html#running-sql-queries-programmatically)                      |
