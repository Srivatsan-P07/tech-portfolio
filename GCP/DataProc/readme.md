### ðŸ“˜ **Apache Spark on Google Cloud Dataproc - Course Content**

| **Module** | **Topic** | **Description** |
|------------|--------------------------------------------|
| 1 | Introduction to Dataproc | What is Dataproc, key features, advantages over traditional clusters |
| 2 | Setting Up Google Cloud Environment | Creating a GCP account, enabling billing, setting up IAM roles & permissions |
| 3 | Creating Dataproc Clusters | Using Console, gcloud CLI, Terraform basics (optional) |
| 4 | Cluster Configuration | Choosing machine types, autoscaling, custom initialization scripts |
| 5 | Running Spark Jobs on Dataproc | Submitting jobs (Console, gcloud, REST API), PySpark/Scala jobs |
| 6 | Working with Cloud Storage (GCS) | Reading/writing data from GCS, configuring Spark to access buckets |
| 7 | Spark SQL and DataFrames on Dataproc | Executing SQL jobs using Spark SQL and BigQuery connector |
| 8 | Dataproc Workflow Templates | Automating job workflows using templates and parameterization |
| 9 | Integrating with BigQuery | Using Spark-BigQuery connector, read/write to BigQuery |
| 10 | Monitoring and Logging | Stackdriver (Cloud Logging), job history, Spark UI on Dataproc |
| 11 | Performance Tuning on Dataproc | Autoscaling, preemptible VMs, caching, shuffling optimization |
| 12 | Securing Dataproc | VPCs, service accounts, encryption, identity-aware access |
| 13 | Dataproc Serverless (optional/advanced) | Using Spark without cluster management (Dataproc Serverless) |
| 14 | Cost Optimization | Using preemptible VMs, autoscaling policies, shutting down idle clusters |
| 15 | Final Project | Deploy an end-to-end Spark job on Dataproc, integrating GCS and BigQuery |